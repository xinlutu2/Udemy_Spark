{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 343.375)\n",
      "(19, 213.27272727272728)\n",
      "(20, 165.0)\n",
      "(21, 350.875)\n",
      "(22, 206.42857142857142)\n",
      "(23, 246.3)\n",
      "(24, 233.8)\n",
      "(25, 197.45454545454547)\n",
      "(26, 242.05882352941177)\n",
      "(27, 228.125)\n",
      "(28, 209.1)\n",
      "(29, 215.91666666666666)\n",
      "(30, 235.8181818181818)\n",
      "(31, 267.25)\n",
      "(32, 207.9090909090909)\n",
      "(33, 325.3333333333333)\n",
      "(34, 245.5)\n",
      "(35, 211.625)\n",
      "(36, 246.6)\n",
      "(37, 249.33333333333334)\n",
      "(38, 193.53333333333333)\n",
      "(39, 169.28571428571428)\n",
      "(40, 250.8235294117647)\n",
      "(41, 268.55555555555554)\n",
      "(42, 303.5)\n",
      "(43, 230.57142857142858)\n",
      "(44, 282.1666666666667)\n",
      "(45, 309.53846153846155)\n",
      "(46, 223.69230769230768)\n",
      "(47, 233.22222222222223)\n",
      "(48, 281.4)\n",
      "(49, 184.66666666666666)\n",
      "(50, 254.6)\n",
      "(51, 302.14285714285717)\n",
      "(52, 340.6363636363636)\n",
      "(53, 222.85714285714286)\n",
      "(54, 278.0769230769231)\n",
      "(55, 295.53846153846155)\n",
      "(56, 306.6666666666667)\n",
      "(57, 258.8333333333333)\n",
      "(58, 116.54545454545455)\n",
      "(59, 220.0)\n",
      "(60, 202.71428571428572)\n",
      "(61, 256.22222222222223)\n",
      "(62, 220.76923076923077)\n",
      "(63, 384.0)\n",
      "(64, 281.3333333333333)\n",
      "(65, 298.2)\n",
      "(66, 276.44444444444446)\n",
      "(67, 214.625)\n",
      "(68, 269.6)\n",
      "(69, 235.2)\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"FriendsByAge\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)\n",
    "\n",
    "lines = sc.textFile(\"file:////home/user/Desktop/spark/average_age/fakefriends.csv\")\n",
    "rdd = lines.map(parseLine)\n",
    "totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "averagesByAge = totalsByAge.mapValues(lambda x: x[0] / x[1])\n",
    "results = averagesByAge.collect()\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the shakespeare data into an [RDD](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) by using [`textFile`](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext.textFile). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
